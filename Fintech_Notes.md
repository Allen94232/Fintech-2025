# Fintech 學習筆記

## 動態規劃 (Dynamic Programming)

### DP 基本概念
1. **Define** the optimum-value function for recursion
2. **Derive** the recurrent formula of the optimum-value function, with boundary conditions
3. **Specify** the answer to the original task in terms of the optimum-value function
4. **Decomposition**: The original problem can be expressed in terms of subproblems
5. **Subproblem optimality**: the global optimum value of a subproblem can be defined in terms of optimal subproblems of smaller sizes
6. Any DP problem can be visualized as this optimal path finding problem!
7. We need to store back-tracking information in order to identify the path efficiently
8. Once the optimal path is found, all the related sub-problems are also solved
9. DP can only find the optimal path. To find the second best, we need to resort to a more complicated n-best approach
10. A problem of size n is solved by first solving all sub-problems of sizes k, where k < n

### DP for Stock Trading
- **基本公式**: `pn = 第n天價格`, `sn = 第n天持股`, `cn = 第n天現金`
  - `sn = max(sn-1, cn-1 / pn)`
  - `cn = max(cn-1, sn-1 * pn)`

- **含交易費用**: `p = 交易手續費率`
  - `sn = max(sn-1, cn-1 * (1 - p) / pn)`
  - `cn = max(cn-1, sn-1 * pn * (1 - p))`

---

## 台股基礎知識

### 市場規模
- **上市**: 973 家
- **上櫃**: 835 家
- **總計**: 1,808 家公司
- **漲跌幅限制**: 每日 ±10%

### 投資報酬率比較
- **銀行定存**: ~1.2%
- **台股平均殖利率**: ~4%
- **Yield (殖利率)** = 股利 / 股價

### 交易流程
```
委託下單 → 券商 → 集中交易市場撮合 → 交易完成 → 交割 (T+2)
```

### 交易時間
- **一般交易**: 週一至週五 09:00-13:30
- **盤後交易**: 13:30-14:00 (只能下單，不能撤單)

### 交易單位
- **整股**: 1張 = 1,000股
- **零股**: 1-999股
- **股價**: 以1股價格計價

### 交易成本
- **手續費**: 交易金額 × 0.1425% (最低20元，買賣各計一次)
- **證交稅**: 賣出時額外加 0.3%

---

## 投資分析四面向

### 基本面
公司獲利能力、財務狀況

### 技術面
- **指標法**: 均線、RSI等技術指標
- **型態學**: 頭肩頂、雙底等圖形

### 籌碼面
大戶買賣動向

### 消息面
政策、新聞

---

## 財務指標

### ROI (投資報酬率)
```
ROI = (賣出價格 - 買入價格 + 股利) / 買入價格 = 收益 / 成本
```

### 除權息
- **除息**: 股價下跌 = 除息前股價 - 現金股利
- **除權**: 股價下跌 = 除權前股價 / (1 + 股票股利/10)
- **同時除權息**: `(除權息前股價 - 現金股利) / (1 + 股票股利/10)`

### EPS (每股盈餘)
```
EPS = 稅後淨利 / 普通股股數
```

### PER (本益比)
```
PER = 股價 / EPS
```
- 股價相同 → EPS 越高越好
- EPS 相同 → 股價越低越好
- 都不同 → PER 越低越好

### PBR (股價淨值比)
```
PBR = 股價 / 每股淨值 = 股價 / (股東權益 / 普通股股數)
```
→ PBR 越低越好

### 配股與配息
- **配股**: 以股票發放股利 (股東權益不變，持股比例不變，股價下跌)
- **配息**: 以現金發放股利 (股東權益減少，持股比例不變，股價下跌)
- **配息率**:
  - 股票配息率 = 每股股票股利 / EPS × 100%
  - 現金配息率 = 每股現金股利 / EPS × 100%

### 其他財務指標
- **股本** = 普通股股數 × 每股面額 (台灣每股面額10元)
- **市值** = 股價 × 普通股股數
- **ROA** (資產報酬率) = 稅後淨利 / 總資產
- **ROE** (股東權益報酬率) = 稅後淨利 / 股東權益 → 越高越好

### ETF (指數股票型基金)
追蹤特定指數表現，可在交易所買賣的共同基金

---

## 風險與報酬指標

### Sharpe Ratio (夏普率)
```
SR = (每日報酬率平均 - 無風險利率) / 每日報酬率標準差
```

**計算步驟**:
1. 每日報酬率 = (今日股價 - 昨日股價) / 昨日股價
2. 計算報酬率的平均值和標準差
3. SR日 = (平均 - 無風險利率/252) / 標準差
4. SR月 = (平均 - 無風險利率/12) / 標準差

**年化換算**:
- SR年 = SR日 × √252
- SR年 = SR月 × √12

夏普比率越高 → 單位風險可獲得更高報酬

---

## 複利與報酬率

### 複利公式
```
A = P(1 + r/n)^(nt)
```
- A = 未來值
- P = 現值
- r = 年利率
- n = 每年複利次數
- t = 投資年限

### IRR (年化報酬率)
```
IRR = (1 + 總報酬率)^(1/n) - 1
```
其中 n = 投資年限

### IRR 計算方法
現金流量不同時，找一個 r 使得 NPV = 0:
```
NPV = Σ [Ct / (1 + r)^t]
```
- t = 年份 (從0開始)
- Ct = 第t年現金流量

**重要**: 股票 IRR 應用還原股價計算，不能僅用資本利得+股息 (會因除權息低估報酬率)

---

## 房貸計算

### 每月應付本息
```
月付款 = P × [r(1 + r)^n] / [(1 + r)^n - 1]
```
- P = 貸款本金
- r = 月利率 = 年利率/12
- n = 貸款總期數 (月)

---

## 技術分析指標

### MA (移動平均線)
**定義**: 一段時間內的平均價格，代表平均成本

**計算**:
```
nMA = Σ(近n日收盤價) / n
```
天數不足n天時，用現有天數計算

**常用均線**:
- 週線: 5MA
- 月線: 20MA
- 季線: 60MA
- 半年線: 120MA
- 年線: 240MA

**分類**:
- 短期: 5MA, 10MA
- 中期: 20MA, 60MA
- 長期: 120MA, 240MA

**交易策略**:
- 股價 > 均線 → 買進
- 股價 < 均線 → 賣出
- **黃金交叉**: 短期均線 > 長期均線 → 買進
- **死亡交叉**: 短期均線 < 長期均線 → 賣出

### RSI (相對強弱指標)
```
RSI = [SMAu / (SMAu + SMAd)] × 100%
```
- SMAu = n日內上漲收盤價變動平均 = Σ(漲幅) / n
- SMAd = n日內下跌收盤價變動平均 = Σ(跌幅) / n

**交易策略** (n=14 最具代表性):
- RSI > 70% → 超買區 (股價可能下跌)
- RSI < 30% → 超賣區 (股價可能上漲)
- **黃金交叉**: RSI短期線上穿長期線 → 買進
- **死亡交叉**: RSI短期線下穿長期線 → 賣出

---

## 投資組合最佳化 (Portfolio Optimization)

**注意**: 不適合資本量小的投資人

### 符號定義
- σ = 風險 (標準差)
- μ = 報酬 (平均數)
- w = 權重

### 標準差公式
```
σ = √[Σ(xi - μ)² / (N-1)]
```

### 兩資產組合
**資產**: a₁, a₂  
**權重**: w₁, w₂ (w₁ + w₂ = 1)  
**平均報酬**: μ₁, μ₂  
**變異數**: σ₁², σ₂²  
**共變異數**: σ₁₂

**組合報酬**:
```
μp = w₁μ₁ + w₂μ₂
```

**組合變異數**:
```
σp² = w₁²σ₁² + w₂²σ₂² + 2w₁w₂σ₁₂
```

### 效率前緣 (Efficient Frontier)
```
σp² = [1/(μ₂-μ₁)²] × [(σ₁²-2σ₁₂+σ₂²)μp² - 2(μ₂σ₁²-(μ₁+μ₂)σ₁₂+μ₁σ₂²)μp + (μ₂²σ₁²-2μ₁μ₂σ₁₂+μ₁²σ₂²)]
```

### 最小變異組合 (MVP)
```
w₁ = (σ₂² - ρ₁₂σ₁σ₂) / (σ₁² + σ₂² - 2ρ₁₂σ₁σ₂)
w₂ = 1 - w₁
```

### 相關係數影響
- **ρ₁₂ = 1**: 效率前緣為直線
- **ρ₁₂ = -1**: 效率前緣為 V 型
- **|ρ₁₂| < 1**: 效率前緣為拋物線

### 零風險組合條件
當 ρ₁₂ = -1 且:
```
w₁ = σ₂ / (σ₁ + σ₂)
w₂ = σ₁ / (σ₁ + σ₂)
```
→ 最小變異數 = 0，報酬 = (μ₁σ₂ + μ₂σ₁) / (σ₁ + σ₂)

### 不同相關係數下的最小變異數

#### ρ₁₂ = 1
```
σ = min(σ₁, σ₂)
w₁ = 1 if σ₁ < σ₂ else 0
```

#### ρ₁₂ = 0
```
σ = (σ₁σ₂) / √(σ₁² + σ₂²)
w₁ = σ₂² / (σ₁² + σ₂²)
w₂ = σ₁² / (σ₁² + σ₂²)
```

#### ρ₁₂ = -1
```
σ = 0
w₁ = σ₂ / (σ₁ + σ₂)
w₂ = σ₁ / (σ₁ + σ₂)
```

### 斜率計算
- ρ₁₂ = 1: slope = (μ₂ - μ₁) / |σ₂ - σ₁|
- ρ₁₂ = 0: slope = (μ₂ - μ₁) / √(σ₁² + σ₂²)
- ρ₁₂ = -1: slope = (μ₂ - μ₁) / (σ₁ + σ₂)

### n 資產組合 (矩陣形式)
```
μp = μᵀw
σp² = wᵀΣw
```

### 常用最佳化目標
- min σ² = wᵀΣw
- max μp = μᵀw
- max (μp - μ₀) / σp (夏普比率最大化)
- max (μp - βσp) (調整夏普比率最大化)

---

## AM-GM 不等式應用

### 基本不等式
```
(x₁ + x₂ + ... + xn) / n ≥ (x₁ × x₂ × ... × xn)^(1/n)
```
等號成立 ⟺ x₁ = x₂ = ... = xn

### 應用範例

#### 1. 無頂長方體 (最大體積)
表面積 S = xy + 2xz + 2yz
```
S/3 ≥ (xy × 2xz × 2yz)^(1/3)
```
體積最大時: xy = 2xz = 2yz = S/3

#### 2. 無頂正方底長方體
表面積 S = x² + 4xz
```
S/3 ≥ (x² × 2xz × 2xz)^(1/3)
```
體積最大時: x² = 2xz = S/3

#### 3. 無頂圓柱體
表面積 S = πr² + 2πrh
```
S/3 ≥ (πr² × πrh × πrh)^(1/3)
```
體積最大時: πr² = 2πrh = S/3

#### 4. 無頂圓錐
表面積 S = √(r² + h²) × πr
```
S²/3 ≥ (r⁸ × h⁴ × π⁴)^(1/3)
```
體積最大時: π²r⁴ = ½π²r²h² = S²/3

#### 5. 四角剪裁問題
從邊長 L 的正方形四角各剪掉邊長 h 的小正方形，求最大體積:
```
V = (L - 2h)² × h = 4h³ - 4Lh² + L²h
V ≤ L³/27
```
等號成立時: h = L/6，邊長:高 = 4:1

---

## 機器學習基礎

### K-means Clustering
1. 需要初始聚類中心或初始分割
2. 迭代過程保證收斂
3. 基於座標優化概念
4. 屬於非監督式學習

### Imbalanced Dataset
**定義**: 某些類別樣本數遠多於其他類別，導致模型偏向預測多數類別

**適用評估指標**: AUPRC, F-measure, AUROC

### NIST 手寫數字資料集
- 訓練資料: 60,000 筆
- 測試資料: 10,000 筆
- 格式: 28×28 像素灰階圖像 (數字 0-9)

### Z-Normalization
```
z = (x - μ) / σ
```
- μ = 平均值
- σ = 標準差
- z-score 代表數據點距離平均值的標準差倍數

---

## 自然語言處理

### TF-IDF
**用途**: 評估詞語在文件集合中的重要性

**公式**:
```
TF(t) = t在文件中出現次數 / 文件總詞數
IDF(t) = log(總文件數 / 包含t的文件數)
TF-IDF(t) = TF(t) × IDF(t)
```

### BM-25
```
TF(t) = ((k+1) × f(t,D)) / (k × ((1-b) + b × (|DL|/avgDL)) + f(t,D))
```
- f(t,D) = t 在文件 D 中出現次數
- |DL| = 文件 D 的長度
- avgDL = 所有文件的平均長度
- k₁ ∈ [1.2, 2]
- b = 0.75

### 中文斷詞

#### 白痴造句法
利用諧音或斷句改變詞的原意

#### 詞庫斷詞法
根據預先建立的詞庫進行匹配

**優點**:
- 速度快且實作簡單
- 只需比對詞庫中的詞語

**缺點**:
- 無法識別詞庫中不存在的新詞
- 對多義詞和歧義詞處理較差
- 需要定期更新詞庫

**常用方法**:
- **FMM** (Forward Maximum Matching): 正向最大匹配 (從左到右)
- **RMM** (Reverse Maximum Matching): 反向最大匹配 (從右到左)

→ 取 N 字詞庫中長度最大的詞進行匹配

---

## 模型評估指標

### Confusion Matrix (混淆矩陣)
- TP (True Positive): 真陽性
- FP (False Positive): 假陽性
- TN (True Negative): 真陰性
- FN (False Negative): 假陰性

### 基本指標
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
TPR = TP / (TP + FN) = 1 - FNR
FPR = FP / (FP + TN) = 1 - TNR
Precision = TP / (TP + FP)
Recall = TPR
F-measure = 2 × (Precision × Recall) / (Precision + Recall)
```

### Threshold (閾值) 影響
- θ 變大 → TPR↓, FPR↓, Recall↓, DET↓, ROC↑
- likelihood > θ → 分類為 positive
- likelihood ≤ θ → 分類為 negative

### ROC Curve
- X 軸: FPR
- Y 軸: TPR
- 端點: (0,0) 和 (1,1)

### DET Curve
- X 軸: FPR
- Y 軸: FNR
- 端點: (0,1) 和 (1,0)
- 兩軸使用常態分佈刻度

### AUROC (ROC 曲線下面積)
- 範圍: 0.5 ~ 1.0
- 隨機猜測: 0.5
- 完美分類器: 1.0

### PRC (Precision-Recall Curve)
- X 軸: Recall
- Y 軸: Precision
- **最大 likelihood 為 positive**: 端點 (0,1), (1, P/(N+P))
- **最大 likelihood 為 negative**: 端點 (0,0), (1, P/(N+P))

### mAP (平均精度均值)
```
AP@k = Σ(precision@i × indicator(hit@i)) / hits數量
```
- i = 1 to k
- indicator(hit@i) = 1 (命中) 或 0 (未命中)
- mAP = Σ(AP@k for each query) / 查詢總數

### Cost Matrix
```
CTP = 0, CTN = 0, CFP = 1, CFN = A (大數)
總成本 f(θ) = A × FN(θ) + FP(θ)
arc(min(f(θ))) = AUROC
```

### 錯誤率指標
- S = Substitutions (替換錯誤)
- D = Deletions (刪除錯誤)
- I = Insertions (插入錯誤)
- C = Correct (正確數)
- N = 總數

```
WER (Word Error Rate) = (S + D + I) / N
CER (Character Error Rate) = (S + D + I) / N
MER (Mix Error Rate) = Chinese -> Character ; English -> Word
ASR (Average Success Rate) = 正確預測數 / 總預測數
```

---

## 特徵選擇 (Feature Selection)

### 事前決定
1. Model (模型)
2. Performance index (性能指標)
3. Performance evaluation method (評估方法)

### 優點
- ✓ 更好的準確率
- ✓ 更少的計算量
- ✓ 特徵與輸出間的可解釋性

### Feature Extraction vs Feature Selection
- **Feature Extraction**: 透過線性或非線性組合萃取新特徵 (如 PCA, LDA)
- **Feature Selection**: 從原始特徵中選擇最佳子集

### One Pass Ranking
1. 根據單一 feature 評分並降序排序
2. 選擇前 k 個 feature

**複雜度**: 2n - 1 次 CV  
**優點**: 簡單快速  
**缺點**: 忽略特徵間相互影響

### SFS (Sequential Forward Selection)
1. 選準確率最高的 feature 作為初始集合
2. 每次從剩下的 feature 中選擇一個加入，使準確率最高
3. 重複直到所有 feature 都被選過

**複雜度**: n(n+1)/2 次 CV  
**優點**: 快速且考慮特徵間相互影響  
**缺點**: 無法保證全域最優解

### SBS (Sequential Backward Selection)
1. 將所有 feature 作為初始集合
2. 每次從集合中移除一個 feature，使準確率最高
3. 重複直到只剩一個 feature

**複雜度**: n(n+1)/2 次 CV  
**優點**: 快速且考慮特徵間相互影響  
**缺點**: 無法保證全域最優解

### ES (Exhaustive Search)
1. 產生所有特徵組合並評估
2. 選擇準確率最高的組合

**複雜度**: 2ⁿ - 1 次 CV  
**優點**: 能找到全域最優解  
**缺點**: 計算量大且耗時

### 時間複雜度比較
假設 n 個輸入輸出，建立模型時間: na sec，評估模型時間: mb sec

**訓練時間 + 評估時間**:
- **One Pass Ranking**: (n²+3n-2)/2
- **SFS**: n(n+1)(n+2)/6
- **SBS**: n(n+1)(n+2)/6
- **ES**: n × 2^(n-1)

**從 n 個選最多 k 個**:
- **One Pass Ranking**: n+k-1
- **SFS**: k(2n-k+1)/2
- **SBS**: 3k(k+1)/2 - k(k+1)
- **ES**: C(n,k) = n! / (k!(n-k)!)

---

## 梯度下降 (Gradient Descent)

### 基本特性
1. 性能高度依賴起始點和步長
2. 可使用動量項減少之字形路徑
3. 可用於可微分目標函數（允許有限個不可微點）
4. 可用於最小化 y(x) = |x|

### 梯度計算
```
∇f = (∂f/∂x, ∂f/∂y, ∂f/∂z)
```

### 更新公式
```
新點 = 當前點 - α × ∇f(當前點)
```
α = 步長 (step size)

### 常用函數導數與原函數關係

#### 1. Sigmoid
```
y = 1 / (1 + e^(-x))
y' = y(1 - y)
```

#### 2. Tanh
```
y = (1 - e^(-x)) / (1 + e^(-x))
y' = (1 - y²) / 2
```

#### 3. Softplus
```
y = ln(1 + e^x)
y' = 1 - e^(-y)
```

#### 4. Softsign
```
y = x / (1 + |x|)
y' = (1 - |y|)²
```

### 方向導數
方向向量 v = (a, b)  
單位向量 u = v/||v|| = (a/√(a²+b²), b/√(a²+b²))

```
Duf(x,y) = ∇f(x,y) · u = (∂f/∂x × a + ∂f/∂y × b) / √(a² + b²)
```

### 矩陣梯度公式
```
∇(cᵀx) = c
∇(xᵀx) = 2x
∇(cᵀAx) = Aᵀc
∇(xᵀAc) = Ac
∇(xᵀAx) = (A + Aᵀ)x
```
若 A 對稱: ∇(xᵀAx) = 2Ax

---

## 最大似然估計 (MLE)

### 基本概念
```
似然函數: L(θ|x) = P(x|θ)
對數似然函數: ll(θ|x) = ln(L(θ|x)) = ln(P(x|θ))
```

若有 n₁, n₂, ...:
```
max L(p₁, p₂, p₃) = n₁ln(p₁) + n₂ln(p₂) + n₃ln(p₃)
```

### 常態分佈 PDF

#### 1D
```
g(x|μ,σ²) = (1/√(2πσ²)) × e^(-(x-μ)²/(2σ²))
```
- x = 數據點
- μ = 平均值
- σ² = 變異數

#### nD
```
g(x|μ,Σ) = (1/((2π)^(n/2)|Σ|^(1/2))) × e^(-½(x-μ)ᵀΣ⁻¹(x-μ))
```
- x = 數據點 (n×1)
- μ = 平均值 (n×1)
- Σ = 共變異數矩陣 (n×n)

### Poisson 分佈
```
P(x;λ) = (λ^x × e^(-λ)) / x!
```
λ = 平均發生率

**MLE**:
```
max L(λ) = Σ(ni × ln(λ) - λ - ln(ni!))
λ = Σni / N
```

### 均勻分佈
```
PDF: u(x;a,b) = 1/(b-a)  for a ≤ x ≤ b
```

**MLE**:
```
max L(a,b) = -N × ln(b-a)
a = min(xi), b = max(xi)
```

---

## 多層感知器 (MLP)

### 架構
由輸入層、隱藏層、輸出層組成 (m × n × p)

### 決策邊界設計
**二維平面**:
- 輸入層 = 2
- 一條線 → 隱藏層 = 1
- Convex → 隱藏層 = 2
- Arbitrary → 隱藏層 ≥ 3
- 輸出層 = 1

### MLP 特性
1. 三層 MLP 可近似任何複雜決策邊界
2. 激活函數必須連續（允許有限個不可微點）
3. 動量項可幫助梯度下降避免局部最小值
4. 梯度下降是訓練 MLP 最常用的方法

### XOR 問題權重
找直線方程式 = 1 → w 分別為 x₁, x₂ 的係數

---

## 數學工具

### 點到直線距離
點 (a, b) 到直線 Ax + By + C = 0 的距離:
```
d = |aA + bB + C| / √(A² + B²)
```

### 最小化誤差
- **最小絕對誤差**: arg min_s Σ|s - xi| → s = 中位數
- **最小平方誤差**: arg min_s Σ(s - xi)² → s = 平均數

### 二次型 (Quadratic Form)
```
Q(x) = xᵀAx
```
A = n×n 對稱矩陣

假設 n=3, f = ax² + by² + cz² + dxy + eyz + fxz:
```
A = [a,   d/2, f/2]
    [d/2, b,   e/2]
    [f/2, e/2, c  ]
```

### 期望值與變異數
```
E(X) = μ (平均值)
V(X) = E[(X - E(X))²] = E(X²) - (E(X))² = σ²
V(X) = Σ(xi - μ)² / (N-1)

E(aX + bY) = aE(X) + bE(Y)
V(aX + bY) = a²V(X) + b²V(Y)
```

### 共變異數矩陣
假設 X, Y:
```
C = [V(X),      Cov(X,Y)]
    [Cov(Y,X),  V(Y)    ]

Cov(X,Y) = E[(X-E(X))(Y-E(Y))] = E(XY) - E(X)E(Y)
Cov(X,Y) = Σ(xi-μx)(yi-μy) / (N-1)
```

### PDF 圖特徵值
- **Mode**: max y 時的 x (多個取中間值或區間)
- **Median**: 將面積分成兩半的 x
- **Mean**: 圖的重心 x

三角形: 頂點 x 的平均值  
多個圖形: 各圖形 mean 的加權平均（權重為面積比例）

---

## 最佳化演算法

### 決策支援系統 (DSS)
1. 無需計算梯度
2. 可能困在局部最優
3. 有許多變體

### 遺傳演算法 (GAs)
1. 與基於導數的方法相比較慢
2. 可輕易平行化
3. 成功高度依賴編碼方式
4. 可找到全域最優

### 模擬退火 (SA)
1. 與基於導數的方法相比較慢
2. 無需計算梯度
3. 可找到全域最優

---

## Lagrange 乘數法

**用途**: 在約束條件下尋找函數極值

在 ax + by = c 約束下，找 f(x,y) 的極值:
```
L(x,y,λ) = f(x,y) + λ(ax + by - c)
```

對 L 分別對 x, y, λ 求偏導並設為 0，解聯立方程式

### 熵函數應用
```
f(p₁,p₂,...,pn) = -Σ(pi × ln(pi))
```
約束: Σpi = 1

- **最小值**: 某個 pi = 1，其他 = 0 → f = 0
- **最大值**: 所有 pi = 1/n → f = ln(n)

---

## 主成分分析 (PCA)

### PCA 特性
1. 非監督式降維演算法
2. 可用於尋找最佳擬合超平面（總最小平方）
3. 對稱矩陣有正交特徵向量（對應不同特徵值）
4. 計算共變異數前必須進行零均值化

### 2D 平面投影步驟

**1. 中心化**:
```
Xc = X - mean(X)
```

**2. 計算共變異數矩陣**:
```
(n-1)C = XcXcᵀ
```

**3. 求特徵值**:
```
det((n-1)C - λI) = 0
```
得到 λ₁, λ₂

**4. 真實特徵值**:
```
真實特徵值 = λ / (n-1)
```
取較大者 → variance

**5. 第二主成分** (取較小 λ):
```
((n-1)C - λI)[a,b]ᵀ = 0
```
解出 a, b (λ 不用除 (n-1))

### 向量投影
向量 v₂ 在 v₁ 上的投影:
```
projection = (v₂·v₁) / ||v₁|| = (x₂x₁ + y₂y₁) / √(x₁² + y₁²)
```

---

## 交叉驗證 (Cross Validation)

### k-fold CV
將數據分成 k 個子集，每次用 k-1 個訓練，1 個測試，重複 k 次

**時間複雜度**:
假設 n 個數據，建立模型: na sec，評估模型: mb sec
- 每次訓練資料量 = (k-1)n/k
- 測試資料量 = n/k
- **總時間** = k × [(k-1)n/k × a + n/k × b] = (k-1)na + nb

### Leave-One-Out CV (LOOCV)
k-fold CV 的特例，k = n

**總時間** = n × [(n-1)a + b] = n(n-1)a + nb

### LOOCV 特性
1. 耗時且不適合訓練時間長的分類器（如神經網路）
2. 充分利用數據集得到客觀的準確率估計
3. 可用於客觀決定模型複雜度

### Stratified m-fold CV
每個 fold 的類別比例與原始資料集相同

---

## 區塊鏈與比特幣

### 橢圓曲線加密
```
2P = P + P
y² = x³ + ax + b
```

**P(x₁, y₁), Q(x₂, y₂)**:
```
x₃ = m² - x₁ - x₂
y₃ = m(x₁ - x₃) - y₁
```

**斜率**:
- P = Q: m = (3x₁² + a) / (2y₁)
- P ≠ Q: m = (y₂ - y₁) / (x₂ - x₁)

### 錢包類型
- **Hot wallet**: 連接網路的比特幣錢包
- **Cold wallet**: 離線比特幣錢包，用於長期儲存

### 比特幣技術細節
1. **Hash 演算法**: SHA-256
2. **隱私交易**: Zcash
3. **量子威脅**: ECDSA 未來可能被破解 → 改用 PQC
4. **加密基元**: ECDSA, SHA-2, RIPEMD-160
5. **當前價格**: ~USD 90,000
6. **區塊價值**: 由 Merkle Root 決定
7. **交易流程**: 公鑰 → hash → 簽章

### 比特幣網路運作步驟
1. 新交易廣播至所有節點
2. 節點收集交易成區塊
3. 節點尋找工作量證明
4. 廣播區塊至所有節點
5. 節點驗證交易有效性和是否已花費
6. 節點接受區塊，使用該區塊 hash 作為下一個區塊的前置 hash

### 區塊 Hash 特徵
SHA-256 開頭有多個 0

### 量子電腦適用問題
少輸入少輸出但狀態/選擇很多:
- 路徑尋找
- 組合最佳化
- 整數分解
- 分子模擬
- 投資組合最佳化

---

## 附錄: 完整公式索引

本筆記涵蓋以下主題:
- 動態規劃與股票交易
- 台股基礎知識與交易規則
- 財務指標 (ROI, EPS, PER, PBR, ROE, ROA)
- 風險報酬指標 (Sharpe Ratio)
- 複利計算與 IRR
- 技術分析 (MA, RSI)
- 投資組合最佳化
- AM-GM 不等式應用
- 機器學習基礎
- NLP 與斷詞
- 模型評估指標 (ROC, DET, AUROC, PRC)
- 特徵選擇方法
- 梯度下降與最佳化
- 最大似然估計 (MLE)
- 多層感知器 (MLP)
- 主成分分析 (PCA)
- 交叉驗證 (CV)
- 區塊鏈與比特幣

---

*最後更新: 2025年12月*
